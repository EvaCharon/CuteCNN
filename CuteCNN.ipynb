{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pylab as plt\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import utils\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "class CuteCNN:\n",
    "    def __init__(self):\n",
    "        self.model=Sequential()\n",
    "        \n",
    "    def build(self,loss='MSE', optimizer='adam',activation='relu'):\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 3), activation=activation,padding='same'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(32, 32, 1), activation=activation,padding='same'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(16, 16, 1), activation=activation,padding='same'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=(8, 8, 1), activation=activation,padding='same'))\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(64, activation=activation))\n",
    "        self.model.add(Dense(10, activation='softmax'))\n",
    "        self.model.compile(loss=loss, optimizer=optimizer , metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "        return self.model\n",
    "    \n",
    "    def train_model(self,x_train, y_train, _loss='MSE', _optimizer='adam',_activation='relu',\n",
    "                    _validation_split=0.2, _batch_size=100, _epochs=1, _verbose=2):\n",
    "        self.build(loss=_loss, optimizer=_optimizer)\n",
    "        self.model.fit(x_train, y_train, validation_split=_validation_split, \n",
    "                       batch_size=_batch_size, epochs=_epochs, verbose=_verbose)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def evaluate_model(self,x_test,y_test):\n",
    "        if len(self.model.layers) == 0:\n",
    "            print(\"The model hasn't been built.\")\n",
    "            return\n",
    "        loss, accuracy = self.model.evaluate(x_test,y_test)\n",
    "        print(\"The test loss of is %f, the accuracy is %f\" % (loss, accuracy))\n",
    "        return loss, accuracy\n",
    "    \n",
    "    def save_model(self,filename):\n",
    "        self.model.save(filename)\n",
    "    \n",
    "    def load_weights(self,filename):\n",
    "        if len(self.model.layers) == 0:\n",
    "            self.build()\n",
    "        self.model.load_weights(filename)\n",
    "        \n",
    "    def picture_predict(self,img):\n",
    "        if len(self.model.layers) == 0:\n",
    "            print(\"The model hasn't been built.\")\n",
    "            return\n",
    "        classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "        scores = self.model.predict(img)\n",
    "        catagory = np.argmax(scores)\n",
    "        score = scores[0][catagory]       \n",
    "        print(\"Class: \"+classes[catagory])\n",
    "        print(\"Probability: \"+ str(score))\n",
    "        return score, classes[catagory]\n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import cifar10\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_cifar_dataset():\n",
    "    print(\"Load cifar10 dataset...\")\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print('y_test shape:', y_test.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print(\"------------------------------\")\n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    y_test = np_utils.to_categorical(y_test)\n",
    "    \n",
    "    return x_train/255, y_train, x_test/255, y_test\n",
    "\n",
    "def classify_picture(img_filename,network):\n",
    "    img = cv2.imread(img_filename)\n",
    "    img = cv2.resize(img, (32,32))\n",
    "    #plot images\n",
    "    fig = plt.figure(figsize=(5,2))    \n",
    "    img1 = img.reshape((1,32,32,3))\n",
    "    score,result = network.picture_predict(img1)\n",
    "    plt.title(\"Class: \"+result+\" Probability: \"+ str(score))\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    return score,result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cifar10 dataset...\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "y_test shape: (10000, 1)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "------------------------------\n",
      "WARNING:tensorflow:From C:\\Users\\charo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 37,546\n",
      "Trainable params: 37,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\charo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "LOSS = 'MSE'\n",
    "OPTIMIZER = 'adam'\n",
    "ACTIVATION = 'relu'\n",
    "VALIDATION_SPLIT=0.2\n",
    "BATCH_SIZE=100\n",
    "EPOCHS=10\n",
    "\n",
    "save_model_path=\"\"\n",
    "load_model_path=\"\"\n",
    "\n",
    "img_path=\"\"\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = load_cifar_dataset()\n",
    "    network = CuteCNN()\n",
    "    if load_model_path == \"\":\n",
    "        network.train_model(x_train,y_train,_loss=LOSS, _optimizer=OPTIMIZER,_activation=ACTIVATION,\n",
    "                    _validation_split=VALIDATION_SPLIT, _batch_size=BATCH_SIZE, _epochs=EPOCHS, _verbose=2)\n",
    "        if save_model_path != \"\":\n",
    "            network.save_model(save_model_path)\n",
    "    else:\n",
    "        print(\"Loading Weights from existing file...\")\n",
    "        network.load_weights(load_model_path)\n",
    "    network.evaluate_model(x_test,y_test)\n",
    "    \n",
    "    if img_path !=\"\":\n",
    "        classify_picture(img_path,network)\n",
    "    del x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
